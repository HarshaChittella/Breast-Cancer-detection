# -*- coding: utf-8 -*-
"""MobileNet.ipynb

Author: Harsha Vardhan Chittella

Automatically generated by Colaboratory.

"""
# importing all the libraries and functions
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score
from tensorflow.keras.layers import LSTM, Reshape
from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.neural_network import MLPClassifier

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
import re
import numpy as np  # linear algebra
import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)

import os

# pip install openpyxl

# importing all the libraries and functions
from tensorflow import keras
import cv2
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt
from tensorflow.keras import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, BatchNormalization
from tensorflow.keras.layers import Dense, Activation
from tensorflow.keras.layers import Flatten, Dropout, SpatialDropout2D, AveragePooling2D, GlobalAveragePooling2D
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

# Please change path with respect to your location for this to work
path = r'D:\Study\AI Fundamentals\Assignment\Dataset_BUSI_with_GT'
dir_list = [os.path.join(path, i) for i in os.listdir(path)]
size_dict = {}
for i, value in enumerate(dir_list):
    size_dict[os.listdir(path)[i]] = len(os.listdir(value))
size_dict


def clean(name):
    name = re.sub('[benign ().p]', '', str(name))
    return name


# creating a data frame
df = pd.DataFrame(os.listdir(dir_list[0]))

df = df[0].apply(clean)

df = df[~df.str.contains('mask', regex=False)]  # differentiating masked images

df_list = list(df)
type(df_list)
df_list.sort()
print(len(df_list))

# Declaring Variables
img_size = 128
img_channel = 3
X_b, Xm_b, y_b = np.zeros((437, img_size, img_size, img_channel)), np.zeros(
    (437, img_size, img_size, img_channel)), np.full(437, 'benign')
X_n, Xm_n, y_n = np.zeros((133, img_size, img_size, img_channel)), np.zeros(
    (133, img_size, img_size, img_channel)), np.full(133, 'normal')
X_m, Xm_m, y_m = np.zeros((210, img_size, img_size, img_channel)), np.zeros(
    (210, img_size, img_size, img_channel)), np.full(210, 'malignant')

img1_path = os.path.join(os.path.join(path, 'benign'),
                         os.listdir(os.path.join(path, 'benign'))[1])

pil_img = load_img(img1_path, color_mode='rgb',
                   target_size=(img_size, img_size))
img = img_to_array(pil_img)
img_shape = img.shape
print(img_shape)


def img_num(filename):

    val = 0

    for i in range(len(filename)):
        if filename[i] == '(':
            while True:
                i += 1
                if filename[i] == ')':
                    break
                val = (val*10) + int(filename[i])
            break

    return val


for tumor_path in dir_list:
    for image in os.listdir(tumor_path):
        p = os.path.join(tumor_path, image)
        # read image as  grayscale ans resize it
        pil_img = load_img(p, color_mode='rgb',
                           target_size=(img_size, img_size))

        if image[-5] == ')':                                  # if real image

            if image[0] == 'b':
                # If image is real add it to X as benign , normalor malignant.
                X_b[img_num(image)-1] += img_to_array(pil_img)
            if image[0] == 'n':
                X_n[img_num(image)-1] += img_to_array(pil_img)
            if image[0] == 'm':
                X_m[img_num(image)-1] += img_to_array(pil_img)
        else:                                                  # else masked image

            if image[0] == 'b':
                # Similarly add the target mask to y.
                Xm_b[img_num(image)-1] += img_to_array(pil_img)
            if image[0] == 'n':
                Xm_n[img_num(image)-1] += img_to_array(pil_img)
            if image[0] == 'm':
                Xm_m[img_num(image)-1] += img_to_array(pil_img)

X = np.concatenate((X_b, X_n, X_m), axis=0)      #
Xm = np.concatenate((Xm_b, Xm_n, Xm_m), axis=0)  # concatenate all the images
y = np.concatenate((y_b, y_n, y_m), axis=0)      #

print(X.shape)
print(Xm.shape)
print(y.shape)
X /= 255.0
Xm /= 255.0

print(X.max())
print(Xm.min())


encoder = OneHotEncoder()
# y = y.toarray()
y = encoder.fit_transform(y.reshape(y.shape[0], 1))

# train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.15, shuffle=True, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(
    X_train, y_train, test_size=0.1, random_state=42, stratify=y_train.toarray())
Xm_train, Xm_test, ym_train, ym_test = train_test_split(
    Xm, y, test_size=0.15, shuffle=True, random_state=42, stratify=y.toarray())
Xm_train, Xm_val, ym_train, ym_val = train_test_split(
    Xm_train, ym_train, test_size=0.1, random_state=42, stratify=ym_train.toarray())

class_list = encoder.categories_
print(X_train.shape, X_test.shape)
print(y_train.shape, y_test.shape)

# BASE MODEL
base_model = tf.keras.applications.MobileNetV2(
    include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape=img_shape,
    pooling=None
)
# Features
X_feat_out = base_model.output
X_feat_flatten = Flatten()(X_feat_out)

X_feat_model = Model(inputs=base_model.input, outputs=X_feat_flatten)
X_feat_train = X_feat_model.predict(X_train)
X_feat_val = X_feat_model.predict(X_val)
X_feat_test = X_feat_model.predict(X_test)


Xm_feat_train = X_feat_model.predict(Xm_train)
Xm_feat_val = X_feat_model.predict(Xm_val)
Xm_feat_test = X_feat_model.predict(Xm_test)


df = pd.DataFrame(columns=['classifier', "train_accuracy", 'val_accuracy',
                  "test_accuracy", "f1_measure", "kappa_score", "recall", "Precision"])

# Evaluate function that gives the optputs


def eval(classifier_name, y_train, y_train_pred, y_val, y_val_pred, y_true, y_pred):
    y_train = np.argmax(y_train, axis=1)
#     y_train_pred = np.argmax(y_train_pred,axis=1)
    y_val = np.argmax(y_val, axis=1)
#     y_val_pred = np.argmax(y_val_pred,axis=1)
    y_true = np.argmax(y_true, axis=1)
   # y_pred = np.argmax(y_pred,axis=1)

    # ALL The outputs and scores required
    train_accuracy = round(accuracy_score(y_train, y_train_pred), 4)
    val_accuracy = round(accuracy_score(y_val, y_val_pred), 4)
    test_accuracy = round(accuracy_score(y_true, y_pred), 4)
    f1_measure = round(f1_score(y_true, y_pred, average='weighted'), 4)
    kappa_score = round(cohen_kappa_score(y_true, y_pred), 4)
    recall = round(recall_score(y_true, y_pred, average='weighted'), 4)
    precision = round(precision_score(y_true, y_pred, average='weighted'), 4)

    cm = confusion_matrix(y_true, y_pred)  # Confusion Matrix
    print(cm)
    sns.heatmap(cm, annot=True)  # Heat MAP for confusion Matrix
    plt.show()

    # Appending to a list
    score = {"classifier": classifier_name, "train_accuracy": train_accuracy, "val_accuracy": val_accuracy,
             "test_accuracy": test_accuracy, "f1_measure": f1_measure, "kappa_score": kappa_score, "recall": recall, "precision": precision}

# Appending to Dataframe
    df.loc[len(df.index)] = score.values()
    for e, a in score.items():
        print(e, a)
    print("--"*20)

# Classifier evluation function that gives inputs


def classifier_eval(classifier, classifier_name, X_train, y_train, X_val, y_val, X_test, y_test):

    classifier.fit(X_train, np.argmax(y_train, axis=1))

    y_train_pred = classifier.predict(X_train)
    y_val_pred = classifier.predict(X_val)
    y_test_pred = classifier.predict(X_test)

    eval(classifier_name, y_train, y_train_pred,
         y_val, y_val_pred, y_test, y_test_pred)


# ADDing all the models to a list
names = ['SVM',
         'Random Forest',
         'KNN',
         'ANN'
         ]

classifier = [
    SVC(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    MLPClassifier(max_iter=400),
]

cls_list = zip(names, classifier)
clsm_list = zip(names, classifier)
# Running all the models in loop
for n, c in cls_list:
    classifier_eval(c, n, X_feat_train, y_train.toarray(),
                    X_feat_val, y_val.toarray(), X_feat_test, y_test.toarray())
# LSTM model
for l in base_model.layers:
    l.trainable = False

lstm_model = Sequential()
lstm_model.add(base_model)
lstm_model.add(Reshape(
    (base_model.output.shape[1]*base_model.output.shape[2], base_model.output.shape[3])))
lstm_model.add(LSTM(128, dropout=0.5, recurrent_dropout=0.5))
lstm_model.add(Dense(3, activation='softmax'))

lstm_model.compile(
    optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])


es = EarlyStopping(monitor='val_loss', mode='min', patience=4,
                   restore_best_weights=True, verbose=1)

history = lstm_model.fit(X_train, y_train.toarray(
), epochs=20, validation_data=(X_val, y_val.toarray()), callbacks=[es])
lstm_train_predict = np.argmax(lstm_model.predict(X_train), axis=1)
lstm_val_predict = np.argmax(lstm_model.predict(X_val), axis=1)
lstm_test_predict = np.argmax(lstm_model.predict(X_test), axis=1)
eval("LSTM", y_train, lstm_train_predict, y_val,
     lstm_val_predict, y_test, lstm_test_predict)


print(df)

# exporting dataframe to excel file
df.to_excel("MobileNetV2.xlsx", index=False)


# Running loop for masked images
df = pd.DataFrame(columns=['classifier', "train_accuracy", 'val_accuracy',
                  "test_accuracy", "f1_measure", "kappa_score", "recall", "Precision"])
for n, c in clsm_list:
    classifier_eval(c, n, Xm_feat_train, ym_train.toarray(
    ), Xm_feat_val, ym_val.toarray(), Xm_feat_test, ym_test.toarray())

# Masked images for lstm model
history = lstm_model.fit(Xm_train, ym_train.toarray(
), epochs=20, validation_data=(Xm_val, ym_val.toarray()), callbacks=[es])
lstm_train_predict = np.argmax(lstm_model.predict(Xm_train), axis=1)
lstm_val_predict = np.argmax(lstm_model.predict(Xm_val), axis=1)
lstm_test_predict = np.argmax(lstm_model.predict(Xm_test), axis=1)
eval("LSTM", ym_train, lstm_train_predict, ym_val,
     lstm_val_predict, ym_test, lstm_test_predict)


print(df)
# exporting dataframe to excel file
df.to_excel("MobileNetV2_m.xlsx", index=False)
